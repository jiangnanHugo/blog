I"C+<p><code class="language-plaintext highlighter-rouge">sparse_block_dot</code> is a special function in Theano.</p>

<h4 id="1-function">1. Function</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">o</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">h</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">o</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">numpy</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">W</span><span class="p">[</span><span class="n">iIdx</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">oIdx</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">j</span><span class="p">]])</span>
</code></pre></div></div>

<p><strong>Image Example</strong>
<img src="http://deeplearning.net/software/theano/_images/blocksparse.png" alt="Images" /></p>

<p><strong>Input Parameter</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- W (iBlocks, oBlocks, iSize, oSize) – weight matrix
- h (batch, iWin, iSize) – input from lower layer (sparse)
- inputIdx (batch, iWin) – indexes of the input blocks
- b (oBlocks, oSize) – bias vector
- outputIdx (batch, oWin) – indexes of the output blocks
</code></pre></div></div>

<p><strong>Return</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- dot(W[i, j], h[i]) + b[j] #but b[j] is only added once
- shape: (batch, oWin, oSize)
</code></pre></div></div>

<h4 id="2-applications">2. Applications</h4>
<p>used form calculating <code class="language-plaintext highlighter-rouge">theano.tensor.nnet.h_softmax</code>;</p>

<p><strong>Codes</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">h_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">n_outputs_per_class</span><span class="p">,</span>
              <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="c1"># "Two-level hierarchical softmax."
</span>    <span class="c1"># First softmax that computes the probabilities of belonging to each class
</span>    <span class="n">class_probs</span> <span class="o">=</span> <span class="n">theano</span><span class="p">.</span><span class="n">tensor</span><span class="p">.</span><span class="n">nnet</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>  <span class="c1"># Computes the probabilites of all the outputs
</span>        <span class="c1"># Second softmax that computes the output probabilities
</span>        <span class="n">activations</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">b2</span>
        <span class="n">output_probs</span> <span class="o">=</span> <span class="n">theano</span><span class="p">.</span><span class="n">tensor</span><span class="p">.</span><span class="n">nnet</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="n">activations</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_outputs_per_class</span><span class="p">)))</span>
        <span class="n">output_probs</span> <span class="o">=</span> <span class="n">output_probs</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">output_probs</span> <span class="o">=</span> <span class="n">class_probs</span><span class="p">.</span><span class="n">dimshuffle</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'x'</span><span class="p">)</span> <span class="o">*</span> <span class="n">output_probs</span>
        <span class="n">output_probs</span> <span class="o">=</span> <span class="n">output_probs</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1"># output_probs.shape[1] is n_classes * n_outputs_per_class, which might
</span>        <span class="c1"># be greater than n_outputs, so we ignore the potential irrelevant
</span>        <span class="c1"># outputs with the next line:
</span>        <span class="n">output_probs</span> <span class="o">=</span> <span class="n">output_probs</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_outputs</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># Computes the probabilities of the outputs specified by the targets
</span>        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="c1"># Classes to which belong each target
</span>        <span class="n">target_classes</span> <span class="o">=</span> <span class="n">target</span> <span class="o">//</span> <span class="n">n_outputs_per_class</span>
        <span class="c1"># Outputs to which belong each target inside a class
</span>        <span class="n">target_outputs_in_class</span> <span class="o">=</span> <span class="n">target</span> <span class="o">%</span> <span class="n">n_outputs_per_class</span>

        <span class="c1"># Second softmax that computes the output probabilities
</span>        <span class="n">activations</span> <span class="o">=</span> <span class="n">sparse_block_dot</span><span class="p">(</span>
            <span class="n">W2</span><span class="p">.</span><span class="n">dimshuffle</span><span class="p">(</span><span class="s">'x'</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> 
            <span class="n">x</span><span class="p">.</span><span class="n">dimshuffle</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s">'x'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">tensor</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int32'</span><span class="p">),</span> 
            <span class="n">b2</span><span class="p">,</span>
            <span class="n">target_classes</span><span class="p">.</span><span class="n">dimshuffle</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s">'x'</span><span class="p">))</span>

        <span class="n">output_probs</span> <span class="o">=</span> <span class="n">theano</span><span class="p">.</span><span class="n">tensor</span><span class="p">.</span><span class="n">nnet</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">activations</span><span class="p">.</span><span class="n">dimshuffle</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">target_class_probs</span> <span class="o">=</span> <span class="n">class_probs</span><span class="p">[</span><span class="n">tensor</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span>
                                         <span class="n">target_classes</span><span class="p">]</span>
        <span class="n">output_probs</span> <span class="o">=</span> <span class="n">output_probs</span><span class="p">[</span><span class="n">tensor</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span>
                                    <span class="n">target_outputs_in_class</span><span class="p">]</span>
        <span class="n">output_probs</span> <span class="o">=</span> <span class="n">target_class_probs</span> <span class="o">*</span> <span class="n">output_probs</span>
    <span class="k">return</span> <span class="n">output_probs</span>
</code></pre></div></div>
:ET