I"<p>Sampling from multiple discrete items with diverse probability is relatively <strong>slow</strong>. When applying the noise contrastive estimation method, the intuitive sampling method becomes a bottleneck for the model’s training. So we apply the alias method for generating samples from the given noise distribution.</p>

<h4 id="generate-samples">Generate Samples</h4>
<p>if you want to generate many samples from the distribution, and don’t want specific tokens to be appear.</p>
<ol>
  <li>generate 1 sample, check whether this sample is not equal to your specific token. then loop though this step, until you get as much samples as you want. (slow)</li>
  <li>generate 3 times more samples and remove the specific tokens in this list. (relatively faster)</li>
</ol>

<h4 id="references">References</h4>
<ol>
  <li><a href="http://cgi.cs.mcgill.ca/~enewel3/posts/alias-method/index.html">Sampling from Many Discrete Outcomes: the Alias Method</a></li>
  <li><a href="https://github.com/asmith26/Vose-Alias-Method">Python implementation of Vose’s alias method</a></li>
  <li><a href="https://github.com/jiangnanhugo/lmkit/tree/master/nce">language model with NCE via alias method</a></li>
  <li><a href="http://www.keithschwarz.com/darts-dice-coins/">Darts, Dice, and Coins: Sampling from a Discrete Distribution</a></li>
  <li><a href="https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/">The Alias Method: Efficient Sampling with Many Discrete Outcomes</a></li>
</ol>
:ET